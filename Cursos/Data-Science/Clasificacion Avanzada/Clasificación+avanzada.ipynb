{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación avanzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente ejemplo fue tomado de la documentación oficial de scikit-learn \n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', \n",
    "              'comp.graphics', 'sci.med']\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', \n",
    "                                  categories=categories, \n",
    "                                  shuffle=True, random_state=42)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=categories, \n",
    "                                 shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X_train_tf = TfidfVectorizer(use_idf=False).fit_transform(twenty_train.data)\n",
    "X_train_tf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', SVC(kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9207723035952063"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "# Calculamos accuracy:\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train = tf_idf.fit_transform(twenty_train.data)\n",
    "X_test = tf_idf.transform(twenty_test.data)\n",
    "y_train = twenty_train.target\n",
    "y_test = twenty_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.9207723035952063\n",
      "SGDClassifier 0.914780292942743\n",
      "VotingClassifier 0.9300932090545939\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "svc_clf = SVC(kernel='linear', probability=True) #  para soft\n",
    "sgd_clf = SGDClassifier(loss='log') # para soft\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('svc', svc_clf), ('sgd', sgd_clf)],voting='soft')\n",
    "\n",
    "\n",
    "for clf in (svc_clf, sgd_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    #SVC 0.9207723035952063\n",
    "#SGDClassifier 0.9247669773635153\n",
    "#VotingClassifier 0.9241011984021305"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7203728362183754"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=200, n_jobs=-1)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7989347536617842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8042609853528628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=200, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   n_estimators=1500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(\n",
    "     DecisionTreeClassifier(max_depth=1), n_estimators=1500,\n",
    "     algorithm=\"SAMME.R\"\n",
    " )\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8215712383488681"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:48:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8621837549933422"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge lightgbm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.23124\n",
      "[2]\tvalid_0's multi_logloss: 1.11646\n",
      "[3]\tvalid_0's multi_logloss: 1.023\n",
      "[4]\tvalid_0's multi_logloss: 0.945858\n",
      "[5]\tvalid_0's multi_logloss: 0.878616\n",
      "[6]\tvalid_0's multi_logloss: 0.817269\n",
      "[7]\tvalid_0's multi_logloss: 0.768198\n",
      "[8]\tvalid_0's multi_logloss: 0.724117\n",
      "[9]\tvalid_0's multi_logloss: 0.686055\n",
      "[10]\tvalid_0's multi_logloss: 0.65002\n",
      "[11]\tvalid_0's multi_logloss: 0.616503\n",
      "[12]\tvalid_0's multi_logloss: 0.587707\n",
      "[13]\tvalid_0's multi_logloss: 0.564735\n",
      "[14]\tvalid_0's multi_logloss: 0.540743\n",
      "[15]\tvalid_0's multi_logloss: 0.517917\n",
      "[16]\tvalid_0's multi_logloss: 0.49996\n",
      "[17]\tvalid_0's multi_logloss: 0.483758\n",
      "[18]\tvalid_0's multi_logloss: 0.469801\n",
      "[19]\tvalid_0's multi_logloss: 0.455247\n",
      "[20]\tvalid_0's multi_logloss: 0.4451\n",
      "[21]\tvalid_0's multi_logloss: 0.435949\n",
      "[22]\tvalid_0's multi_logloss: 0.423442\n",
      "[23]\tvalid_0's multi_logloss: 0.414759\n",
      "[24]\tvalid_0's multi_logloss: 0.406735\n",
      "[25]\tvalid_0's multi_logloss: 0.400667\n",
      "[26]\tvalid_0's multi_logloss: 0.396664\n",
      "[27]\tvalid_0's multi_logloss: 0.391695\n",
      "[28]\tvalid_0's multi_logloss: 0.386993\n",
      "[29]\tvalid_0's multi_logloss: 0.383087\n",
      "[30]\tvalid_0's multi_logloss: 0.380208\n",
      "[31]\tvalid_0's multi_logloss: 0.375806\n",
      "[32]\tvalid_0's multi_logloss: 0.372519\n",
      "[33]\tvalid_0's multi_logloss: 0.368844\n",
      "[34]\tvalid_0's multi_logloss: 0.366234\n",
      "[35]\tvalid_0's multi_logloss: 0.364157\n",
      "[36]\tvalid_0's multi_logloss: 0.359987\n",
      "[37]\tvalid_0's multi_logloss: 0.359685\n",
      "[38]\tvalid_0's multi_logloss: 0.35734\n",
      "[39]\tvalid_0's multi_logloss: 0.355918\n",
      "[40]\tvalid_0's multi_logloss: 0.35238\n",
      "[41]\tvalid_0's multi_logloss: 0.350291\n",
      "[42]\tvalid_0's multi_logloss: 0.349205\n",
      "[43]\tvalid_0's multi_logloss: 0.348648\n",
      "[44]\tvalid_0's multi_logloss: 0.34648\n",
      "[45]\tvalid_0's multi_logloss: 0.345499\n",
      "[46]\tvalid_0's multi_logloss: 0.343753\n",
      "[47]\tvalid_0's multi_logloss: 0.342665\n",
      "[48]\tvalid_0's multi_logloss: 0.342412\n",
      "[49]\tvalid_0's multi_logloss: 0.342515\n",
      "[50]\tvalid_0's multi_logloss: 0.341953\n",
      "[51]\tvalid_0's multi_logloss: 0.343417\n",
      "[52]\tvalid_0's multi_logloss: 0.343514\n",
      "[53]\tvalid_0's multi_logloss: 0.343095\n",
      "[54]\tvalid_0's multi_logloss: 0.342119\n",
      "[55]\tvalid_0's multi_logloss: 0.34179\n",
      "[56]\tvalid_0's multi_logloss: 0.341819\n",
      "[57]\tvalid_0's multi_logloss: 0.343086\n",
      "[58]\tvalid_0's multi_logloss: 0.343005\n",
      "[59]\tvalid_0's multi_logloss: 0.345223\n",
      "[60]\tvalid_0's multi_logloss: 0.344967\n",
      "[61]\tvalid_0's multi_logloss: 0.345835\n",
      "[62]\tvalid_0's multi_logloss: 0.344487\n",
      "[63]\tvalid_0's multi_logloss: 0.345804\n",
      "[64]\tvalid_0's multi_logloss: 0.347508\n",
      "[65]\tvalid_0's multi_logloss: 0.349009\n",
      "[66]\tvalid_0's multi_logloss: 0.348655\n",
      "[67]\tvalid_0's multi_logloss: 0.349362\n",
      "[68]\tvalid_0's multi_logloss: 0.349221\n",
      "[69]\tvalid_0's multi_logloss: 0.350739\n",
      "[70]\tvalid_0's multi_logloss: 0.35026\n",
      "[71]\tvalid_0's multi_logloss: 0.350606\n",
      "[72]\tvalid_0's multi_logloss: 0.352019\n",
      "[73]\tvalid_0's multi_logloss: 0.352603\n",
      "[74]\tvalid_0's multi_logloss: 0.354124\n",
      "[75]\tvalid_0's multi_logloss: 0.354474\n",
      "[76]\tvalid_0's multi_logloss: 0.355745\n",
      "[77]\tvalid_0's multi_logloss: 0.356596\n",
      "[78]\tvalid_0's multi_logloss: 0.356565\n",
      "[79]\tvalid_0's multi_logloss: 0.35821\n",
      "[80]\tvalid_0's multi_logloss: 0.35967\n",
      "[81]\tvalid_0's multi_logloss: 0.358492\n",
      "[82]\tvalid_0's multi_logloss: 0.361444\n",
      "[83]\tvalid_0's multi_logloss: 0.363073\n",
      "[84]\tvalid_0's multi_logloss: 0.363838\n",
      "[85]\tvalid_0's multi_logloss: 0.365271\n",
      "[86]\tvalid_0's multi_logloss: 0.366884\n",
      "[87]\tvalid_0's multi_logloss: 0.368931\n",
      "[88]\tvalid_0's multi_logloss: 0.369542\n",
      "[89]\tvalid_0's multi_logloss: 0.370039\n",
      "[90]\tvalid_0's multi_logloss: 0.371381\n",
      "[91]\tvalid_0's multi_logloss: 0.371529\n",
      "[92]\tvalid_0's multi_logloss: 0.373992\n",
      "[93]\tvalid_0's multi_logloss: 0.375877\n",
      "[94]\tvalid_0's multi_logloss: 0.37709\n",
      "[95]\tvalid_0's multi_logloss: 0.378223\n",
      "[96]\tvalid_0's multi_logloss: 0.38026\n",
      "[97]\tvalid_0's multi_logloss: 0.381879\n",
      "[98]\tvalid_0's multi_logloss: 0.384531\n",
      "[99]\tvalid_0's multi_logloss: 0.386914\n",
      "[100]\tvalid_0's multi_logloss: 0.387988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier()\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8861517976031957"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vecstack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-676aa43bb241>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mvecstack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m estimators = [('xgb', xgb_clf),\n\u001b[0;32m      5\u001b[0m               ('ada', ada_clf)]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'vecstack'"
     ]
    }
   ],
   "source": [
    "from vecstack import StackingTransformer\n",
    "\n",
    "\n",
    "estimators = [('xgb', xgb_clf),\n",
    "              ('ada', ada_clf)]\n",
    "              \n",
    "# StackingTransformer\n",
    "stack = StackingTransformer(estimators, regression=False, verbose=2)\n",
    "\n",
    "# Fit\n",
    "stack = stack.fit(X_train, y_train)\n",
    "\n",
    "# stacked features\n",
    "S_train = stack.transform(X_train)\n",
    "S_test = stack.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMClassifier()\n",
    "gbm.fit(S_train, y_train,\n",
    "        eval_set=[(S_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(S_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
