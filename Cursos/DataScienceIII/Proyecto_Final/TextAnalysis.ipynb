{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53019697-7987-4852-ae5b-04e797986fb0",
   "metadata": {},
   "source": [
    "## PyPDF\n",
    "- https://pypi.org/project/pypdf/\n",
    "- https://pypdf.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56766e59-bc57-44bd-8b40-c2f20ba0d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecb6fce4-c10c-4132-af43-40e580e58b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "import spacy\n",
    "spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "import es_core_news_md\n",
    "nlp = es_core_news_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2442ac43-37eb-48eb-b024-6f13a6636cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79cf30bd-968f-4e18-8555-76e5257a95c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "# creating a pdf reader object\n",
    "reader = pypdf.PdfReader('HistoriaDelTiempo.pdf')\n",
    "\n",
    "# print the number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "\n",
    "# print the text of the first page\n",
    "# print(reader.pages[0].extract_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8981f-4b88-4649-99fa-d03dea267ad3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bbc3e47-b6de-408b-a8f1-916687252f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = reader.pages[105].extract_text()\n",
    "doc = nlp(texto)\n",
    "tokens = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fcbdf-1e7f-42bc-a227-dc00e50fb015",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Detección de Oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af563408-2ad8-4a50-aa36-521284346919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de oraciones:\n",
      "7\n",
      "\n",
      "Oraciones:\n",
      "\n",
      "\n",
      "Historia del Tiempo: Del Big Bang a los Agujeros Negros                                                    Stephen Hawking \n",
      " 106\n",
      "gramo.  \n",
      "\n",
      "\n",
      "A pesar de ello, fallarán al final de la vida del agujero negro cuando su masa \n",
      "se haga muy pequeña.  \n",
      "\n",
      "\n",
      "El resultado más probable p arece que será que el agujero \n",
      "negro simplemente desaparecerá, al menos de nuestra región del universo, \n",
      "llevándose con él al astronauta y a cualquier singularidad que pudiera contener, si en \n",
      "verdad hay alguna.  \n",
      "\n",
      "\n",
      "Esto fue la primera indicación de que la mecánica cuántica \n",
      "podría eliminar las singularidades predichas por la teoría de la relatividad.  \n",
      "\n",
      "\n",
      "Sin \n",
      "embargo, los métodos que otros científicos y yo utilizábamos en 1974 no eran \n",
      "capaces de responder a cuestiones como la de si debían existir singularidades en la \n",
      "gravedad cuántica; A partir de 1975, comencé a desarrollar una aproximación más \n",
      "potente a la gravedad cuántica basada en la idea de Feynman de suma sobre las \n",
      "historias posibles.  \n",
      "\n",
      "\n",
      "Las respuestas que esta aproximación sugiere para el origen y \n",
      "destino del universo y de sus contenidos, tales como astronautas, serán descritas en \n",
      "los dos capítulos siguientes.  \n",
      "\n",
      "\n",
      "Se verá que, aunque el principio de incertidumbre \n",
      "establece limitaciones sobre la precisión de nuestras predicciones, podría al mismo \n",
      "tiempo eliminar la incapacidad de predicción de carácter fundamental que ocurre en \n",
      "una singularidad del espacio-tiempo. \n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oraciones= list(doc.sents)\n",
    "print(\"Cantidad de oraciones:\")\n",
    "print(len(oraciones))\n",
    "\n",
    "print(\"\\nOraciones:\\n\\n\")\n",
    "for x in oraciones:\n",
    "    print(x)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae19bb-6e37-4716-b53a-7e23b0204a65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90838f5f-8988-4cad-930c-68d2fa5d5fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historia 0\n",
      "del 9\n",
      "Tiempo 13\n",
      ": 19\n",
      "Del 21\n",
      "Big 25\n",
      "Bang 29\n",
      "a 34\n",
      "los 36\n",
      "Agujeros 40\n",
      "Negros 49\n",
      "                                                    56\n",
      "Stephen 107\n",
      "Hawking 115\n",
      "\n",
      "  123\n",
      "106 125\n",
      "\n",
      " 128\n",
      "gramo 129\n",
      ". 134\n",
      "  136\n",
      "A 137\n",
      "pesar 139\n",
      "de 145\n",
      "ello 148\n",
      ", 152\n",
      "fallarán 154\n",
      "al 163\n",
      "final 166\n",
      "de 172\n",
      "la 175\n",
      "vida 178\n",
      "del 183\n",
      "agujero 187\n",
      "negro 195\n",
      "cuando 201\n",
      "su 208\n",
      "masa 211\n",
      "\n",
      " 216\n",
      "se 217\n",
      "haga 220\n",
      "muy 225\n",
      "pequeña 229\n",
      ". 236\n",
      "  238\n",
      "El 239\n",
      "resultado 242\n",
      "más 252\n",
      "probable 256\n",
      "p 265\n",
      "arece 267\n",
      "que 273\n",
      "será 277\n",
      "que 282\n",
      "el 286\n",
      "agujero 289\n",
      "\n",
      " 297\n",
      "negro 298\n",
      "simplemente 304\n",
      "desaparecerá 316\n",
      ", 328\n",
      "al 330\n",
      "menos 333\n",
      "de 339\n",
      "nuestra 342\n",
      "región 350\n",
      "del 357\n",
      "universo 361\n",
      ", 369\n",
      "\n",
      " 371\n",
      "llevándose 372\n",
      "con 383\n",
      "él 387\n",
      "al 390\n",
      "astronauta 393\n",
      "y 404\n",
      "a 406\n",
      "cualquier 408\n",
      "singularidad 418\n",
      "que 431\n",
      "pudiera 435\n",
      "contener 443\n",
      ", 451\n",
      "si 453\n",
      "en 456\n",
      "\n",
      " 459\n",
      "verdad 460\n",
      "hay 467\n",
      "alguna 471\n",
      ". 477\n",
      "  479\n",
      "Esto 480\n",
      "fue 485\n",
      "la 489\n",
      "primera 492\n",
      "indicación 500\n",
      "de 511\n",
      "que 514\n",
      "la 518\n",
      "mecánica 521\n",
      "cuántica 530\n",
      "\n",
      " 539\n",
      "podría 540\n",
      "eliminar 547\n",
      "las 556\n",
      "singularidades 560\n",
      "predichas 575\n",
      "por 585\n",
      "la 589\n",
      "teoría 592\n",
      "de 599\n",
      "la 602\n",
      "relatividad 605\n",
      ". 616\n",
      "  618\n",
      "Sin 619\n",
      "\n",
      " 623\n",
      "embargo 624\n",
      ", 631\n",
      "los 633\n",
      "métodos 637\n",
      "que 645\n",
      "otros 649\n",
      "científicos 655\n",
      "y 667\n",
      "yo 669\n",
      "utilizábamos 672\n",
      "en 685\n",
      "1974 688\n",
      "no 693\n",
      "eran 696\n",
      "\n",
      " 701\n",
      "capaces 702\n",
      "de 710\n",
      "responder 713\n",
      "a 723\n",
      "cuestiones 725\n",
      "como 736\n",
      "la 741\n",
      "de 744\n",
      "si 747\n",
      "debían 750\n",
      "existir 757\n",
      "singularidades 765\n",
      "en 780\n",
      "la 783\n",
      "\n",
      " 786\n",
      "gravedad 787\n",
      "cuántica 796\n",
      "; 804\n",
      "A 806\n",
      "partir 808\n",
      "de 815\n",
      "1975 818\n",
      ", 822\n",
      "comencé 824\n",
      "a 832\n",
      "desarrollar 834\n",
      "una 846\n",
      "aproximación 850\n",
      "más 863\n",
      "\n",
      " 867\n",
      "potente 868\n",
      "a 876\n",
      "la 878\n",
      "gravedad 881\n",
      "cuántica 890\n",
      "basada 899\n",
      "en 906\n",
      "la 909\n",
      "idea 912\n",
      "de 917\n",
      "Feynman 920\n",
      "de 928\n",
      "suma 931\n",
      "sobre 936\n",
      "las 942\n",
      "\n",
      " 946\n",
      "historias 947\n",
      "posibles 957\n",
      ". 965\n",
      "  967\n",
      "Las 968\n",
      "respuestas 972\n",
      "que 983\n",
      "esta 987\n",
      "aproximación 992\n",
      "sugiere 1005\n",
      "para 1013\n",
      "el 1018\n",
      "origen 1021\n",
      "y 1028\n",
      "\n",
      " 1030\n",
      "destino 1031\n",
      "del 1039\n",
      "universo 1043\n",
      "y 1052\n",
      "de 1054\n",
      "sus 1057\n",
      "contenidos 1061\n",
      ", 1071\n",
      "tales 1073\n",
      "como 1079\n",
      "astronautas 1084\n",
      ", 1095\n",
      "serán 1097\n",
      "descritas 1103\n",
      "en 1113\n",
      "\n",
      " 1116\n",
      "los 1117\n",
      "dos 1121\n",
      "capítulos 1125\n",
      "siguientes 1135\n",
      ". 1145\n",
      "  1147\n",
      "Se 1148\n",
      "verá 1151\n",
      "que 1156\n",
      ", 1159\n",
      "aunque 1161\n",
      "el 1168\n",
      "principio 1171\n",
      "de 1181\n",
      "incertidumbre 1184\n",
      "\n",
      " 1198\n",
      "establece 1199\n",
      "limitaciones 1209\n",
      "sobre 1222\n",
      "la 1228\n",
      "precisión 1231\n",
      "de 1241\n",
      "nuestras 1244\n",
      "predicciones 1253\n",
      ", 1265\n",
      "podría 1267\n",
      "al 1274\n",
      "mismo 1277\n",
      "\n",
      " 1283\n",
      "tiempo 1284\n",
      "eliminar 1291\n",
      "la 1300\n",
      "incapacidad 1303\n",
      "de 1315\n",
      "predicción 1318\n",
      "de 1329\n",
      "carácter 1332\n",
      "fundamental 1341\n",
      "que 1353\n",
      "ocurre 1357\n",
      "en 1364\n",
      "\n",
      " 1367\n",
      "una 1368\n",
      "singularidad 1372\n",
      "del 1385\n",
      "espacio-tiempo 1389\n",
      ". 1403\n",
      "\n",
      "  1405\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token, token.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37be0a0f-fe55-4732-ba4e-f84fece711a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historia 0 Historia  True False False Xxxxx False\n",
      "del 9 del  True False False xxx True\n",
      "Tiempo 13 Tiempo True False False Xxxxx False\n",
      ": 19 :  False True False : False\n",
      "Del 21 Del  True False False Xxx True\n",
      "Big 25 Big  True False False Xxx False\n",
      "Bang 29 Bang  True False False Xxxx False\n",
      "a 34 a  True False False x True\n",
      "los 36 los  True False False xxx True\n",
      "Agujeros 40 Agujeros  True False False Xxxxx False\n",
      "Negros 49 Negros  True False False Xxxxx False\n",
      "                                                    56                                                     False False True      False\n",
      "Stephen 107 Stephen  True False False Xxxxx False\n",
      "Hawking 115 Hawking  True False False Xxxxx False\n",
      "\n",
      "  123 \n",
      "  False False True \n",
      "  False\n",
      "106 125 106 False False False ddd False\n",
      "\n",
      " 128 \n",
      " False False True \n",
      " False\n",
      "gramo 129 gramo True False False xxxx False\n",
      ". 134 .  False True False . False\n",
      "  136   False False True   False\n",
      "A 137 A  True False False X True\n",
      "pesar 139 pesar  True False False xxxx True\n",
      "de 145 de  True False False xx True\n",
      "ello 148 ello True False False xxxx True\n",
      ", 152 ,  False True False , False\n",
      "fallarán 154 fallarán  True False False xxxx False\n",
      "al 163 al  True False False xx True\n",
      "final 166 final  True False False xxxx True\n",
      "de 172 de  True False False xx True\n",
      "la 175 la  True False False xx True\n",
      "vida 178 vida  True False False xxxx False\n",
      "del 183 del  True False False xxx True\n",
      "agujero 187 agujero  True False False xxxx False\n",
      "negro 195 negro  True False False xxxx False\n",
      "cuando 201 cuando  True False False xxxx True\n",
      "su 208 su  True False False xx True\n",
      "masa 211 masa  True False False xxxx False\n",
      "\n",
      " 216 \n",
      " False False True \n",
      " False\n",
      "se 217 se  True False False xx True\n",
      "haga 220 haga  True False False xxxx False\n",
      "muy 225 muy  True False False xxx True\n",
      "pequeña 229 pequeña True False False xxxx False\n",
      ". 236 .  False True False . False\n",
      "  238   False False True   False\n",
      "El 239 El  True False False Xx True\n",
      "resultado 242 resultado  True False False xxxx False\n",
      "más 252 más  True False False xxx True\n",
      "probable 256 probable  True False False xxxx False\n",
      "p 265 p  True False False x False\n",
      "arece 267 arece  True False False xxxx False\n",
      "que 273 que  True False False xxx True\n",
      "será 277 será  True False False xxxx True\n",
      "que 282 que  True False False xxx True\n",
      "el 286 el  True False False xx True\n",
      "agujero 289 agujero  True False False xxxx False\n",
      "\n",
      " 297 \n",
      " False False True \n",
      " False\n",
      "negro 298 negro  True False False xxxx False\n",
      "simplemente 304 simplemente  True False False xxxx False\n",
      "desaparecerá 316 desaparecerá True False False xxxx False\n",
      ", 328 ,  False True False , False\n",
      "al 330 al  True False False xx True\n",
      "menos 333 menos  True False False xxxx True\n",
      "de 339 de  True False False xx True\n",
      "nuestra 342 nuestra  True False False xxxx True\n",
      "región 350 región  True False False xxxx False\n",
      "del 357 del  True False False xxx True\n",
      "universo 361 universo True False False xxxx False\n",
      ", 369 ,  False True False , False\n",
      "\n",
      " 371 \n",
      " False False True \n",
      " False\n",
      "llevándose 372 llevándose  True False False xxxx False\n",
      "con 383 con  True False False xxx True\n",
      "él 387 él  True False False xx True\n",
      "al 390 al  True False False xx True\n",
      "astronauta 393 astronauta  True False False xxxx False\n",
      "y 404 y  True False False x True\n",
      "a 406 a  True False False x True\n",
      "cualquier 408 cualquier  True False False xxxx True\n",
      "singularidad 418 singularidad  True False False xxxx False\n",
      "que 431 que  True False False xxx True\n",
      "pudiera 435 pudiera  True False False xxxx False\n",
      "contener 443 contener True False False xxxx False\n",
      ", 451 ,  False True False , False\n",
      "si 453 si  True False False xx True\n",
      "en 456 en  True False False xx True\n",
      "\n",
      " 459 \n",
      " False False True \n",
      " False\n",
      "verdad 460 verdad  True False False xxxx True\n",
      "hay 467 hay  True False False xxx True\n",
      "alguna 471 alguna True False False xxxx True\n",
      ". 477 .  False True False . False\n",
      "  479   False False True   False\n",
      "Esto 480 Esto  True False False Xxxx True\n",
      "fue 485 fue  True False False xxx True\n",
      "la 489 la  True False False xx True\n",
      "primera 492 primera  True False False xxxx True\n",
      "indicación 500 indicación  True False False xxxx False\n",
      "de 511 de  True False False xx True\n",
      "que 514 que  True False False xxx True\n",
      "la 518 la  True False False xx True\n",
      "mecánica 521 mecánica  True False False xxxx False\n",
      "cuántica 530 cuántica  True False False xxxx False\n",
      "\n",
      " 539 \n",
      " False False True \n",
      " False\n",
      "podría 540 podría  True False False xxxx True\n",
      "eliminar 547 eliminar  True False False xxxx False\n",
      "las 556 las  True False False xxx True\n",
      "singularidades 560 singularidades  True False False xxxx False\n",
      "predichas 575 predichas  True False False xxxx False\n",
      "por 585 por  True False False xxx True\n",
      "la 589 la  True False False xx True\n",
      "teoría 592 teoría  True False False xxxx False\n",
      "de 599 de  True False False xx True\n",
      "la 602 la  True False False xx True\n",
      "relatividad 605 relatividad True False False xxxx False\n",
      ". 616 .  False True False . False\n",
      "  618   False False True   False\n",
      "Sin 619 Sin  True False False Xxx True\n",
      "\n",
      " 623 \n",
      " False False True \n",
      " False\n",
      "embargo 624 embargo True False False xxxx True\n",
      ", 631 ,  False True False , False\n",
      "los 633 los  True False False xxx True\n",
      "métodos 637 métodos  True False False xxxx False\n",
      "que 645 que  True False False xxx True\n",
      "otros 649 otros  True False False xxxx True\n",
      "científicos 655 científicos  True False False xxxx False\n",
      "y 667 y  True False False x True\n",
      "yo 669 yo  True False False xx True\n",
      "utilizábamos 672 utilizábamos  True False False xxxx False\n",
      "en 685 en  True False False xx True\n",
      "1974 688 1974  False False False dddd False\n",
      "no 693 no  True False False xx True\n",
      "eran 696 eran  True False False xxxx True\n",
      "\n",
      " 701 \n",
      " False False True \n",
      " False\n",
      "capaces 702 capaces  True False False xxxx False\n",
      "de 710 de  True False False xx True\n",
      "responder 713 responder  True False False xxxx False\n",
      "a 723 a  True False False x True\n",
      "cuestiones 725 cuestiones  True False False xxxx False\n",
      "como 736 como  True False False xxxx True\n",
      "la 741 la  True False False xx True\n",
      "de 744 de  True False False xx True\n",
      "si 747 si  True False False xx True\n",
      "debían 750 debían  True False False xxxx False\n",
      "existir 757 existir  True False False xxxx False\n",
      "singularidades 765 singularidades  True False False xxxx False\n",
      "en 780 en  True False False xx True\n",
      "la 783 la  True False False xx True\n",
      "\n",
      " 786 \n",
      " False False True \n",
      " False\n",
      "gravedad 787 gravedad  True False False xxxx False\n",
      "cuántica 796 cuántica True False False xxxx False\n",
      "; 804 ;  False True False ; False\n",
      "A 806 A  True False False X True\n",
      "partir 808 partir  True False False xxxx True\n",
      "de 815 de  True False False xx True\n",
      "1975 818 1975 False False False dddd False\n",
      ", 822 ,  False True False , False\n",
      "comencé 824 comencé  True False False xxxx False\n",
      "a 832 a  True False False x True\n",
      "desarrollar 834 desarrollar  True False False xxxx False\n",
      "una 846 una  True False False xxx True\n",
      "aproximación 850 aproximación  True False False xxxx False\n",
      "más 863 más  True False False xxx True\n",
      "\n",
      " 867 \n",
      " False False True \n",
      " False\n",
      "potente 868 potente  True False False xxxx False\n",
      "a 876 a  True False False x True\n",
      "la 878 la  True False False xx True\n",
      "gravedad 881 gravedad  True False False xxxx False\n",
      "cuántica 890 cuántica  True False False xxxx False\n",
      "basada 899 basada  True False False xxxx False\n",
      "en 906 en  True False False xx True\n",
      "la 909 la  True False False xx True\n",
      "idea 912 idea  True False False xxxx False\n",
      "de 917 de  True False False xx True\n",
      "Feynman 920 Feynman  True False False Xxxxx False\n",
      "de 928 de  True False False xx True\n",
      "suma 931 suma  True False False xxxx False\n",
      "sobre 936 sobre  True False False xxxx True\n",
      "las 942 las  True False False xxx True\n",
      "\n",
      " 946 \n",
      " False False True \n",
      " False\n",
      "historias 947 historias  True False False xxxx False\n",
      "posibles 957 posibles True False False xxxx False\n",
      ". 965 .  False True False . False\n",
      "  967   False False True   False\n",
      "Las 968 Las  True False False Xxx True\n",
      "respuestas 972 respuestas  True False False xxxx False\n",
      "que 983 que  True False False xxx True\n",
      "esta 987 esta  True False False xxxx True\n",
      "aproximación 992 aproximación  True False False xxxx False\n",
      "sugiere 1005 sugiere  True False False xxxx False\n",
      "para 1013 para  True False False xxxx True\n",
      "el 1018 el  True False False xx True\n",
      "origen 1021 origen  True False False xxxx False\n",
      "y 1028 y  True False False x True\n",
      "\n",
      " 1030 \n",
      " False False True \n",
      " False\n",
      "destino 1031 destino  True False False xxxx False\n",
      "del 1039 del  True False False xxx True\n",
      "universo 1043 universo  True False False xxxx False\n",
      "y 1052 y  True False False x True\n",
      "de 1054 de  True False False xx True\n",
      "sus 1057 sus  True False False xxx True\n",
      "contenidos 1061 contenidos True False False xxxx False\n",
      ", 1071 ,  False True False , False\n",
      "tales 1073 tales  True False False xxxx False\n",
      "como 1079 como  True False False xxxx True\n",
      "astronautas 1084 astronautas True False False xxxx False\n",
      ", 1095 ,  False True False , False\n",
      "serán 1097 serán  True False False xxxx True\n",
      "descritas 1103 descritas  True False False xxxx False\n",
      "en 1113 en  True False False xx True\n",
      "\n",
      " 1116 \n",
      " False False True \n",
      " False\n",
      "los 1117 los  True False False xxx True\n",
      "dos 1121 dos  True False False xxx True\n",
      "capítulos 1125 capítulos  True False False xxxx False\n",
      "siguientes 1135 siguientes True False False xxxx False\n",
      ". 1145 .  False True False . False\n",
      "  1147   False False True   False\n",
      "Se 1148 Se  True False False Xx True\n",
      "verá 1151 verá  True False False xxxx False\n",
      "que 1156 que True False False xxx True\n",
      ", 1159 ,  False True False , False\n",
      "aunque 1161 aunque  True False False xxxx True\n",
      "el 1168 el  True False False xx True\n",
      "principio 1171 principio  True False False xxxx False\n",
      "de 1181 de  True False False xx True\n",
      "incertidumbre 1184 incertidumbre  True False False xxxx False\n",
      "\n",
      " 1198 \n",
      " False False True \n",
      " False\n",
      "establece 1199 establece  True False False xxxx False\n",
      "limitaciones 1209 limitaciones  True False False xxxx False\n",
      "sobre 1222 sobre  True False False xxxx True\n",
      "la 1228 la  True False False xx True\n",
      "precisión 1231 precisión  True False False xxxx False\n",
      "de 1241 de  True False False xx True\n",
      "nuestras 1244 nuestras  True False False xxxx True\n",
      "predicciones 1253 predicciones True False False xxxx False\n",
      ", 1265 ,  False True False , False\n",
      "podría 1267 podría  True False False xxxx True\n",
      "al 1274 al  True False False xx True\n",
      "mismo 1277 mismo  True False False xxxx True\n",
      "\n",
      " 1283 \n",
      " False False True \n",
      " False\n",
      "tiempo 1284 tiempo  True False False xxxx False\n",
      "eliminar 1291 eliminar  True False False xxxx False\n",
      "la 1300 la  True False False xx True\n",
      "incapacidad 1303 incapacidad  True False False xxxx False\n",
      "de 1315 de  True False False xx True\n",
      "predicción 1318 predicción  True False False xxxx False\n",
      "de 1329 de  True False False xx True\n",
      "carácter 1332 carácter  True False False xxxx False\n",
      "fundamental 1341 fundamental  True False False xxxx False\n",
      "que 1353 que  True False False xxx True\n",
      "ocurre 1357 ocurre  True False False xxxx False\n",
      "en 1364 en  True False False xx True\n",
      "\n",
      " 1367 \n",
      " False False True \n",
      " False\n",
      "una 1368 una  True False False xxx True\n",
      "singularidad 1372 singularidad  True False False xxxx False\n",
      "del 1385 del  True False False xxx True\n",
      "espacio-tiempo 1389 espacio-tiempo False False False xxxx-xxxx False\n",
      ". 1403 .  False True False . False\n",
      "\n",
      "  1405 \n",
      "  False False True \n",
      "  False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token, token.idx, token.text_with_ws,\n",
    "        token.is_alpha, token.is_punct, token.is_space,\n",
    "        token.shape_, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b20baa6-7172-4423-9296-d9efd0aba3ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82575b00-a781-47b2-80bb-4ab296a0047e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521\n",
      "consigue\n",
      "tanto\n",
      "hablan\n",
      "última\n",
      "en\n",
      "algunos\n",
      "cada\n",
      "por\n",
      "todas\n",
      "hacia\n"
     ]
    }
   ],
   "source": [
    "# Saco todas las stopwords del idioma español\n",
    "\n",
    "spacy_stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
    "print(len(spacy_stopwords))\n",
    "for stop_word in list(spacy_stopwords)[:10]:\n",
    "  print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8892bb8e-0664-4179-b8cf-eb12f1aafb09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historia\n",
      "Tiempo\n",
      ":\n",
      "Big\n",
      "Bang\n",
      "Agujeros\n",
      "Negros\n",
      "                                                   \n",
      "Stephen\n",
      "Hawking\n",
      "\n",
      " \n",
      "106\n",
      "\n",
      "\n",
      "gramo\n",
      ".\n",
      " \n",
      ",\n",
      "fallarán\n",
      "vida\n",
      "agujero\n",
      "negro\n",
      "masa\n",
      "\n",
      "\n",
      "haga\n",
      "pequeña\n",
      ".\n",
      " \n",
      "resultado\n",
      "probable\n",
      "p\n",
      "arece\n",
      "agujero\n",
      "\n",
      "\n",
      "negro\n",
      "simplemente\n",
      "desaparecerá\n",
      ",\n",
      "región\n",
      "universo\n",
      ",\n",
      "\n",
      "\n",
      "llevándose\n",
      "astronauta\n",
      "singularidad\n",
      "pudiera\n",
      "contener\n",
      ",\n",
      "\n",
      "\n",
      ".\n",
      " \n",
      "indicación\n",
      "mecánica\n",
      "cuántica\n",
      "\n",
      "\n",
      "eliminar\n",
      "singularidades\n",
      "predichas\n",
      "teoría\n",
      "relatividad\n",
      ".\n",
      " \n",
      "\n",
      "\n",
      ",\n",
      "métodos\n",
      "científicos\n",
      "utilizábamos\n",
      "1974\n",
      "\n",
      "\n",
      "capaces\n",
      "responder\n",
      "cuestiones\n",
      "debían\n",
      "existir\n",
      "singularidades\n",
      "\n",
      "\n",
      "gravedad\n",
      "cuántica\n",
      ";\n",
      "1975\n",
      ",\n",
      "comencé\n",
      "desarrollar\n",
      "aproximación\n",
      "\n",
      "\n",
      "potente\n",
      "gravedad\n",
      "cuántica\n",
      "basada\n",
      "idea\n",
      "Feynman\n",
      "suma\n",
      "\n",
      "\n",
      "historias\n",
      "posibles\n",
      ".\n",
      " \n",
      "respuestas\n",
      "aproximación\n",
      "sugiere\n",
      "origen\n",
      "\n",
      "\n",
      "destino\n",
      "universo\n",
      "contenidos\n",
      ",\n",
      "tales\n",
      "astronautas\n",
      ",\n",
      "descritas\n",
      "\n",
      "\n",
      "capítulos\n",
      "siguientes\n",
      ".\n",
      " \n",
      "verá\n",
      ",\n",
      "principio\n",
      "incertidumbre\n",
      "\n",
      "\n",
      "establece\n",
      "limitaciones\n",
      "precisión\n",
      "predicciones\n",
      ",\n",
      "\n",
      "\n",
      "tiempo\n",
      "eliminar\n",
      "incapacidad\n",
      "predicción\n",
      "carácter\n",
      "fundamental\n",
      "ocurre\n",
      "\n",
      "\n",
      "singularidad\n",
      "espacio-tiempo\n",
      ".\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  if not token.is_stop:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0435642-6247-491e-a72d-0e58312d6f1a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Historia, Tiempo, :, Big, Bang, Agujeros, Negros,                                                    , Stephen, Hawking, \n",
      " , 106, \n",
      ", gramo, .,  , ,, fallarán, vida, agujero, negro, masa, \n",
      ", haga, pequeña, .,  , resultado, probable, p, arece, agujero, \n",
      ", negro, simplemente, desaparecerá, ,, región, universo, ,, \n",
      ", llevándose, astronauta, singularidad, pudiera, contener, ,, \n",
      ", .,  , indicación, mecánica, cuántica, \n",
      ", eliminar, singularidades, predichas, teoría, relatividad, .,  , \n",
      ", ,, métodos, científicos, utilizábamos, 1974, \n",
      ", capaces, responder, cuestiones, debían, existir, singularidades, \n",
      ", gravedad, cuántica, ;, 1975, ,, comencé, desarrollar, aproximación, \n",
      ", potente, gravedad, cuántica, basada, idea, Feynman, suma, \n",
      ", historias, posibles, .,  , respuestas, aproximación, sugiere, origen, \n",
      ", destino, universo, contenidos, ,, tales, astronautas, ,, descritas, \n",
      ", capítulos, siguientes, .,  , verá, ,, principio, incertidumbre, \n",
      ", establece, limitaciones, precisión, predicciones, ,, \n",
      ", tiempo, eliminar, incapacidad, predicción, carácter, fundamental, ocurre, \n",
      ", singularidad, espacio-tiempo, ., \n",
      " ]\n"
     ]
    }
   ],
   "source": [
    "documento_sin_stopword = [token for token in doc if not token.is_stop]\n",
    "print(documento_sin_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fe7068c-ffac-4fa0-84a3-adde981d1932",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historia - Historia\n",
      "del - del\n",
      "Tiempo - Tiempo\n",
      ": - :\n",
      "Del - Del\n",
      "Big - Big\n",
      "Bang - Bang\n",
      "a - a\n",
      "los - el\n",
      "Agujeros - Agujeros\n",
      "Negros - Negros\n",
      "                                                    -                                                    \n",
      "Stephen - Stephen\n",
      "Hawking - Hawking\n",
      "\n",
      "  - \n",
      " \n",
      "106 - 106\n",
      "\n",
      " - \n",
      "\n",
      "gramo - gramo\n",
      ". - .\n",
      "  -  \n",
      "A - a\n",
      "pesar - pesar\n",
      "de - de\n",
      "ello - él\n",
      ", - ,\n",
      "fallarán - fallar\n",
      "al - al\n",
      "final - final\n",
      "de - de\n",
      "la - el\n",
      "vida - vida\n",
      "del - del\n",
      "agujero - agujero\n",
      "negro - negro\n",
      "cuando - cuando\n",
      "su - su\n",
      "masa - masa\n",
      "\n",
      " - \n",
      "\n",
      "se - él\n",
      "haga - hacer\n",
      "muy - mucho\n",
      "pequeña - pequeño\n",
      ". - .\n",
      "  -  \n",
      "El - el\n",
      "resultado - resultado\n",
      "más - más\n",
      "probable - probable\n",
      "p - p\n",
      "arece - arecir\n",
      "que - que\n",
      "será - ser\n",
      "que - que\n",
      "el - el\n",
      "agujero - agujero\n",
      "\n",
      " - \n",
      "\n",
      "negro - negro\n",
      "simplemente - simplemente\n",
      "desaparecerá - desaparecer\n",
      ", - ,\n",
      "al - al\n",
      "menos - menos\n",
      "de - de\n",
      "nuestra - nuestro\n",
      "región - región\n",
      "del - del\n",
      "universo - universo\n",
      ", - ,\n",
      "\n",
      " - \n",
      "\n",
      "llevándose - llevar él\n",
      "con - con\n",
      "él - él\n",
      "al - al\n",
      "astronauta - astronauta\n",
      "y - y\n",
      "a - a\n",
      "cualquier - cualquiera\n",
      "singularidad - singularidad\n",
      "que - que\n",
      "pudiera - poder\n",
      "contener - contener\n",
      ", - ,\n",
      "si - si\n",
      "en - en\n",
      "\n",
      " - \n",
      "\n",
      "verdad - verdad\n",
      "hay - haber\n",
      "alguna - alguno\n",
      ". - .\n",
      "  -  \n",
      "Esto - este\n",
      "fue - ser\n",
      "la - el\n",
      "primera - primero\n",
      "indicación - indicación\n",
      "de - de\n",
      "que - que\n",
      "la - el\n",
      "mecánica - mecánico\n",
      "cuántica - cuántico\n",
      "\n",
      " - \n",
      "\n",
      "podría - poder\n",
      "eliminar - eliminar\n",
      "las - el\n",
      "singularidades - singularidad\n",
      "predichas - predicha\n",
      "por - por\n",
      "la - el\n",
      "teoría - teoría\n",
      "de - de\n",
      "la - el\n",
      "relatividad - relatividad\n",
      ". - .\n",
      "  -  \n",
      "Sin - sin\n",
      "\n",
      " - \n",
      "\n",
      "embargo - embargo\n",
      ", - ,\n",
      "los - el\n",
      "métodos - método\n",
      "que - que\n",
      "otros - otro\n",
      "científicos - científico\n",
      "y - y\n",
      "yo - yo\n",
      "utilizábamos - utilizábar\n",
      "en - en\n",
      "1974 - 1974\n",
      "no - no\n",
      "eran - ser\n",
      "\n",
      " - \n",
      "\n",
      "capaces - capaz\n",
      "de - de\n",
      "responder - responder\n",
      "a - a\n",
      "cuestiones - cuestión\n",
      "como - como\n",
      "la - el\n",
      "de - de\n",
      "si - si\n",
      "debían - deber\n",
      "existir - existir\n",
      "singularidades - singularidad\n",
      "en - en\n",
      "la - el\n",
      "\n",
      " - \n",
      "\n",
      "gravedad - gravedad\n",
      "cuántica - cuántico\n",
      "; - ;\n",
      "A - A\n",
      "partir - partir\n",
      "de - de\n",
      "1975 - 1975\n",
      ", - ,\n",
      "comencé - comenzar\n",
      "a - a\n",
      "desarrollar - desarrollar\n",
      "una - uno\n",
      "aproximación - aproximación\n",
      "más - más\n",
      "\n",
      " - \n",
      "\n",
      "potente - potente\n",
      "a - a\n",
      "la - el\n",
      "gravedad - gravedad\n",
      "cuántica - cuántico\n",
      "basada - basado\n",
      "en - en\n",
      "la - el\n",
      "idea - idea\n",
      "de - de\n",
      "Feynman - Feynman\n",
      "de - de\n",
      "suma - suma\n",
      "sobre - sobre\n",
      "las - el\n",
      "\n",
      " - \n",
      "\n",
      "historias - historia\n",
      "posibles - posible\n",
      ". - .\n",
      "  -  \n",
      "Las - el\n",
      "respuestas - respuesta\n",
      "que - que\n",
      "esta - este\n",
      "aproximación - aproximación\n",
      "sugiere - sugerir\n",
      "para - para\n",
      "el - el\n",
      "origen - origen\n",
      "y - y\n",
      "\n",
      " - \n",
      "\n",
      "destino - destino\n",
      "del - del\n",
      "universo - universo\n",
      "y - y\n",
      "de - de\n",
      "sus - su\n",
      "contenidos - contenido\n",
      ", - ,\n",
      "tales - tal\n",
      "como - como\n",
      "astronautas - astronauta\n",
      ", - ,\n",
      "serán - ser\n",
      "descritas - describir\n",
      "en - en\n",
      "\n",
      " - \n",
      "\n",
      "los - el\n",
      "dos - dos\n",
      "capítulos - capítulo\n",
      "siguientes - siguiente\n",
      ". - .\n",
      "  -  \n",
      "Se - él\n",
      "verá - ver\n",
      "que - que\n",
      ", - ,\n",
      "aunque - aunque\n",
      "el - el\n",
      "principio - principio\n",
      "de - de\n",
      "incertidumbre - incertidumbre\n",
      "\n",
      " - \n",
      "\n",
      "establece - establecer\n",
      "limitaciones - limitación\n",
      "sobre - sobre\n",
      "la - el\n",
      "precisión - precisión\n",
      "de - de\n",
      "nuestras - nuestro\n",
      "predicciones - predicción\n",
      ", - ,\n",
      "podría - poder\n",
      "al - al\n",
      "mismo - mismo\n",
      "\n",
      " - \n",
      "\n",
      "tiempo - tiempo\n",
      "eliminar - eliminar\n",
      "la - el\n",
      "incapacidad - incapacidad\n",
      "de - de\n",
      "predicción - predicción\n",
      "de - de\n",
      "carácter - carácter\n",
      "fundamental - fundamental\n",
      "que - que\n",
      "ocurre - ocurrir\n",
      "en - en\n",
      "\n",
      " - \n",
      "\n",
      "una - uno\n",
      "singularidad - singularidad\n",
      "del - del\n",
      "espacio-tiempo - espacio-tiempo\n",
      ". - .\n",
      "\n",
      "  - \n",
      " \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token, '-', token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a01ef-1a93-47cb-988f-d10bd73cc183",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc63d757-2087-41de-aa76-e084b9167e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Historia del Tiempo: Del Big Bang a los Agujeros Negros                                                    Stephen Hawking  106gramo.  A pesar de ello, fallarán al final de la vida del agujero negro cuando su masa se haga muy pequeña.  El resultado más probable p arece que será que el agujero negro simplemente desaparecerá, al menos de nuestra región del universo, llevándose con él al astronauta y a cualquier singularidad que pudiera contener, si en verdad hay alguna.  Esto fue la primera indicación de que la mecánica cuántica podría eliminar las singularidades predichas por la teoría de la relatividad.  Sin embargo, los métodos que otros científicos y yo utilizábamos en 1974 no eran capaces de responder a cuestiones como la de si debían existir singularidades en la gravedad cuántica; A partir de 1975, comencé a desarrollar una aproximación más potente a la gravedad cuántica basada en la idea de Feynman de suma sobre las historias posibles.  Las respuestas que esta aproximación sugiere para el origen y destino del universo y de sus contenidos, tales como astronautas, serán descritas en los dos capítulos siguientes.  Se verá que, aunque el principio de incertidumbre establece limitaciones sobre la precisión de nuestras predicciones, podría al mismo tiempo eliminar la incapacidad de predicción de carácter fundamental que ocurre en una singularidad del espacio-tiempo.  '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto1 = re.sub('\\n', '', texto) #remover saltos de linea\n",
    "print(type(texto))\n",
    "str(texto1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f85fe73-7ad1-422e-8305-2ef2e99eb536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\n', 16), (' ', 6), ('cuántica', 3), ('\\n ', 2), ('agujero', 2)]\n"
     ]
    }
   ],
   "source": [
    "docWordFreq = nlp(texto1)\n",
    "\n",
    "# Remover stopwords\n",
    "words= [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "from collections import Counter\n",
    "word_freq= Counter(words)\n",
    "\n",
    "# Sacar las 5 mas frecuentes y sus frecuencias\n",
    "common_words= word_freq.most_common(5)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "296f1361-b868-45c2-a6a5-a1adfceaa2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Historia', 'Tiempo', 'Big', 'Bang', 'Agujeros', 'Negros', '                                                   ', 'Stephen', 'Hawking', '106', 'gramo', 'fallarán', 'vida', 'masa', 'haga', 'pequeña', 'resultado', 'probable', 'p', 'arece', 'simplemente', 'desaparecerá', 'región', 'llevándose', 'astronauta', 'pudiera', 'contener', 'indicación', 'mecánica', 'predichas', 'teoría', 'relatividad', 'métodos', 'científicos', 'utilizábamos', '1974', 'capaces', 'responder', 'cuestiones', 'debían', 'existir', '1975', 'comencé', 'desarrollar', 'potente', 'basada', 'idea', 'Feynman', 'suma', 'historias', 'posibles', 'respuestas', 'sugiere', 'origen', 'destino', 'contenidos', 'tales', 'astronautas', 'descritas', 'capítulos', 'siguientes', 'verá', 'principio', 'incertidumbre', 'establece', 'limitaciones', 'precisión', 'predicciones', 'tiempo', 'incapacidad', 'predicción', 'carácter', 'fundamental', 'ocurre', 'espacio-tiempo']\n"
     ]
    }
   ],
   "source": [
    "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89cb399-0252-4480-9c67-74a881539734",
   "metadata": {},
   "source": [
    "#### Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc75042c-dca4-4a4b-90a1-602114bb494c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texto1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m texto1:\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;28mprint\u001b[39m(token, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, token\u001b[38;5;241m.\u001b[39mlemma_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'texto1' is not defined"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "  print(token, '-', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8df48a-8819-4b3b-ae41-ec96c0a9d718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
